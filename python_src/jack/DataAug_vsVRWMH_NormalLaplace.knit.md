---
title: "DataAug_vs_RWMH_NormalLaplace"
author: "Jack Jewson"
date: "22 January 2020"
output: html_document
---

## Data Simulation


```r
library(rmutil)

set.seed(4)
n <- 100
m <- 100
N_rep <- 1

data_obs_H1 <- matrix(NA,nrow=N_rep,ncol=n)
data_obs_H2 <- matrix(NA,nrow=N_rep,ncol=m)
for(i in 1:N_rep){
  data_private_H1 <- rnorm(n,5,2)
  sensitivity <- 2

  privacy_noise <- rlaplace(n, 0, sensitivity)

  data_obs_H1[i,] <- data_private_H1 + privacy_noise
  data_obs_H2[i,] <- rnorm(m,5,2)
}
```

However for now lets just focus on the synthetic data being generated by Hospital 1 (H1). 

## Data Augmentation in stan 



```r
library(rstan)

a_0<-2
b_0<-2
mu_0<-3
kappa_0 <- 1/5
v_0<-1/kappa_0


#http://discourse.mc-stan.org/t/stan-recompile-to-avoid-r-from-crashing/2631
KLBayes_norm_LaplacePrivacy_stan<-stan_model(file="KLBayes_norm_LaplacePrivacy.stan")


KLBayes_norm_LaplacePrivacy_data<-list(n=n,data_obs=matrix(data_obs_H1[1,],nrow=n,ncol=1),mu_m=mu_0,mu_s=v_0,sig_p1=a_0,sig_p2=b_0, sensitivity = sensitivity)
KLBayes_norm_LaplacePrivacy <- sampling(object=KLBayes_norm_LaplacePrivacy_stan,data=KLBayes_norm_LaplacePrivacy_data,warmup = 1000,iter=10000, chains=1, cores=1,control = list(adapt_delta=0.999,stepsize=0.01,max_treedepth = 20))
KLBayes_norm_LaplacePrivacy_params<-extract(KLBayes_norm_LaplacePrivacy)

mean(KLBayes_norm_LaplacePrivacy_params$mu)
mean(KLBayes_norm_LaplacePrivacy_params$sigma2)
var(KLBayes_norm_LaplacePrivacy_params$mu)
var(KLBayes_norm_LaplacePrivacy_params$sigma2)
```


## RWMH from the Normal Laplace Target.


```r
library(VGAM)
log_mills_ratio <- function(z){
  lr <- log1mexp(-pnorm(z,0,1,log=TRUE))-dnorm(z,0,1,log=TRUE)
  print(paste('z:', z, '->', lr))
  return(lr)
}

library(matrixStats)
normal_laplace_lpdf <- function(y, mu, sigma, lambda){
  k <- sigma / lambda
  r <- (y - mu) / sigma
  log_lik <- -log(2 * lambda) + dnorm(r, 0, 1,log=TRUE) + log(exp(log_mills_ratio(k - r))+exp( log_mills_ratio(k + r)))## not numerically stable, need to acess code for logsumexp vectorised!
  return(sum(log_lik))
}

## The log-posterior when fitting the Normal_Laplace convolution.
library(actuar)
target_posterior <- function(data_obs, mu, sigma2, lambda, mu_m, mu_s, sig_p1, sig_p2){
  target <- dinvgamma(sigma2, shape = sig_p1, scale = sig_p2, log = TRUE) + 
            dnorm(mu, mu_m, sqrt(sigma2*mu_s),log=TRUE) + 
            normal_laplace_lpdf(y = data_obs, mu, sigma = sqrt(sigma2), lambda)
  return(target)
}

RWMH <- function(N, log_target, theta_0, prop_sigma){
  p <- length(theta_0)
  theta <- matrix(NA,nrow=N+1,ncol=p)
  log_accept_prob <- rep(NA,)
  theta[1,] <- theta_0
  for(i in 1:N){
    theta_prop <- theta[i,] + rnorm(p,0, prop_sigma)
    log_accept_prob[i] <- min(log(1), log_target(theta_prop) - log_target(theta[i,]))
    if(log(runif(1)) <= log_accept_prob[i]){
      theta[i+1,] <- theta_prop
    } else{
      theta[i+1,] <- theta[i,]
    }
    if((i %% (N/10))==1){
      cat("Iteration", i, "done", "\n")
    }
  }
  return(list("theta" = theta, "log_accept_prob" = log_accept_prob))
}
```


