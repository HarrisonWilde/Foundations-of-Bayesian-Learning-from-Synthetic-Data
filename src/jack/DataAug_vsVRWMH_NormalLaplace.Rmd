---
title: "DataAug_vs_RWMH_NormalLaplace"
author: "Jack Jewson"
date: "22 January 2020"
output: html_document
---

## Data Simulation

```{r data_sim, include=TRUE,echo=TRUE, eval=TRUE,cache=TRUE,results='hide'}
library(rmutil)

set.seed(4)
n <- 100
m <- 100
N_rep <- 1

data_obs_H1 <- matrix(NA,nrow=N_rep,ncol=n)
data_obs_H2 <- matrix(NA,nrow=N_rep,ncol=m)
for(i in 1:N_rep){
  data_private_H1 <- rnorm(n,5,2)
  sensitivity <- 2

  privacy_noise <- rlaplace(n, 0, sensitivity)

  data_obs_H1[i,] <- data_private_H1 + privacy_noise
  data_obs_H2[i,] <- rnorm(m,5,2)
}


```

However for now lets just focus on the synthetic data being generated by Hospital 1 (H1). 

## Data Augmentation in stan 


```{r model_the_noise, include=TRUE,echo=TRUE, eval=TRUE,cache=TRUE,results='hide'}

library(rstan)

a_0<-2
b_0<-5
mu_0<-5
kappa_0 <- 1/5
v_0<-1/kappa_0


#http://discourse.mc-stan.org/t/stan-recompile-to-avoid-r-from-crashing/2631
KLBayes_norm_LaplacePrivacy_stan<-stan_model(file="KLBayes_norm_LaplacePrivacy.stan")


KLBayes_norm_LaplacePrivacy_data<-list(n=n,data_obs=matrix(data_obs_H1[1,],nrow=n,ncol=1),mu_m=mu_0,mu_s=v_0,sig_p1=a_0,sig_p2=b_0, sensitivity = sensitivity)
KLBayes_norm_LaplacePrivacy <- sampling(object=KLBayes_norm_LaplacePrivacy_stan,data=KLBayes_norm_LaplacePrivacy_data,warmup = 500,iter=5500, chains=12, cores=12, control = list(adapt_delta=0.999,stepsize=0.01,max_treedepth = 20))
KLBayes_norm_LaplacePrivacy_params<-extract(KLBayes_norm_LaplacePrivacy)

mean(KLBayes_norm_LaplacePrivacy_params$mu)
mean(KLBayes_norm_LaplacePrivacy_params$sigma2)
var(KLBayes_norm_LaplacePrivacy_params$mu)
var(KLBayes_norm_LaplacePrivacy_params$sigma2)

```


## RWMH from the Normal Laplace Target.

```{r RWMH_NormalLaplace, include=TRUE,echo=TRUE, eval=TRUE,cache=TRUE}
library(VGAM)
log_mills_ratio <- function(z){
  lr <- log(1 - pnorm(z,0,1))-dnorm(z,0,1,log=TRUE)
  print(paste('z:', z, '->', lr))
  return(lr)
}

library(matrixStats)
normal_laplace_lpdf <- function(y, mu, sigma, lambda){
  k <- sigma / lambda
  r <- (y - mu) / sigma
  
  log_lik <- -log(2 * lambda) + dnorm(r, 0, 1,log=TRUE) + log(exp(log_mills_ratio(k - r))+exp( log_mills_ratio(k + r)))## not numerically stable, need to acess code for logsumexp vectorised!
  return(sum(log_lik))
}

## The log-posterior when fitting the Normal_Laplace convolution.
library(actuar)
target_posterior <- function(data_obs, mu, sigma2, lambda, mu_m, mu_s, sig_p1, sig_p2){
  target <- dinvgamma(sigma2, shape = sig_p1, scale = sig_p2, log = TRUE) + 
            dnorm(mu, mu_m, sqrt(sigma2*mu_s),log=TRUE) + 
            normal_laplace_lpdf(y = data_obs, mu, sigma = sqrt(sigma2), lambda)
  return(target)
}

RWMH <- function(N, log_target, theta_0, prop_sigma){
  p <- length(theta_0)
  theta <- matrix(NA,nrow=N+1,ncol=p)
  log_accept_prob <- rep(NA,)
  theta[1,] <- theta_0
  for(i in 1:N){
    theta_prop <- theta[i,] + rnorm(p,0, prop_sigma)
    cat(exp(theta_prop[2]), '\n')
    log_accept_prob[i] <- min(log(1), log_target(theta_prop) - log_target(theta[i,]))
    print(log_accept_prob[i])
    if(log(runif(1)) <= log_accept_prob[i]){
      theta[i+1,] <- theta_prop
    } else{
      theta[i+1,] <- theta[i,]
    }
    if((i %% (N/10))==1){
      cat("Iteration", i, "done", "\n")
    }
  }
  return(list("theta" = theta, "log_accept_prob" = log_accept_prob))
}



```

```{r RWMH_NormalLaplace_run, include=TRUE,echo=TRUE, eval=TRUE,cache=TRUE}

TWMHtest1 <- RWMH(N = 100000, log_target = function(theta){target_posterior(data_obs = data_obs_H1[1,] , mu = theta[1], sigma2 = exp(theta[2]), lambda = sensitivity, mu_m = mu_0, mu_s = v_0, sig_p1 = a_0, sig_p2 = b_0)}, theta_0 = c(0, log(3)), prop_sigma = 0.6)

mean(exp(TWMHtest1$log_accept_prob))

burn <- 1000
thin <- seq(burn+1,100001,by=10)


plot(density(TWMHtest1$theta[thin,1]),xlab=expression(mu),ylab="Density",main="",lwd=3)
lines(density(KLBayes_norm_LaplacePrivacy_params$mu),lwd=3,col="red")
plot(density(exp(TWMHtest1$theta[thin,2])),xlab=expression(sigma^2),ylab="Density",main="",lwd=3)
lines(density(KLBayes_norm_LaplacePrivacy_params$sigma2),lwd=3,col="red")
```
